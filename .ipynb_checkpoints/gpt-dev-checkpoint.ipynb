{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fc3abca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import tiktoken as tt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "984fa541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [......................................................] 1115394 / 1115394"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'input (1).txt'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#download data from the github repo of Angrej Karpathy\n",
    "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "wget.download(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22c812b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the file\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4b8426e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd604a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3eba3e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "train_config = dict(\n",
    "    framework = 'PyTorch',\n",
    "    batch_size = 64, # how many independent sequences will we process in parallel?\n",
    "    block_size = 256, # what is the maximum context length for predictions?\n",
    "    max_iters = 5000,\n",
    "    eval_interval = 500,\n",
    "    learning_rate = 3e-4,\n",
    "    device = 'mps' if torch.backends.mps.is_available() else 'cpu',\n",
    "    eval_iters = 200,\n",
    "    n_embd = 384,\n",
    "    n_head = 6,\n",
    "    n_layer = 6,\n",
    "    dropout = 0.2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0a27b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64, # how many independent sequences will we process in parallel?\n",
    "block_size = 256, # what is the maximum context length for predictions?\n",
    "max_iters = 5000,\n",
    "eval_interval = 500,\n",
    "learning_rate = 3e-4,\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu',\n",
    "eval_iters = 200,\n",
    "n_embd = 384,\n",
    "n_head = 6,\n",
    "n_layer = 6,\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ff389c",
   "metadata": {},
   "source": [
    "## Encoding\n",
    "1. Since NNs cannot work with strings directly we will have to convert our data/text to a number format (int/float) which is done through the tiktoken library.\n",
    "2. the enc object contains the encoding used for 'GPT-2', which we can apply to our data using encode attribute, and reverse it using decode.\n",
    "3. The size of the encoding depends on the type of encoding, 'GPT-2' in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e4a0d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([338025]) torch.int64\n",
      "tensor([ 5962, 22307,    25,   198,  8421,   356,  5120,   597,  2252,    11,\n",
      "         3285,   502,  2740,    13,   198,   198,  3237,    25,   198,  5248,\n",
      "          461,    11,  2740,    13,   198,   198,  5962, 22307,    25,   198,\n",
      "         1639,   389,   477, 12939,  2138,   284,  4656,   621,   284,  1145,\n",
      "          680,    30,   198,   198,  3237,    25,   198,  4965,  5634,    13,\n",
      "        12939,    13,   198,   198,  5962, 22307,    25,   198,  5962,    11,\n",
      "          345,   760,   327,  1872,   385,  1526, 28599,   318,  4039,  4472,\n",
      "          284,   262,   661,    13,   198,   198,  3237,    25,   198,  1135,\n",
      "          760,   470,    11,   356,   760,   470,    13,   198,   198,  5962,\n",
      "        22307,    25,   198,  5756,   514,  1494,   683,    11,   290,   356])\n"
     ]
    }
   ],
   "source": [
    "enc = tt.get_encoding('gpt2')\n",
    "data = torch.tensor(enc.encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad42131",
   "metadata": {},
   "source": [
    "## Splitting Data\n",
    "1. Split the data into training and validation sets to track model performance on unseen/realistc data\n",
    "2. This is done because we do not want the model to 'memorize' or overfit to the data. We want it to be able to generalize and capture the 'essence' or patterns of Shakespeare's work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "252d9c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0502899",
   "metadata": {},
   "source": [
    "## block_size\n",
    "1. block_size defines the size of the data that is fed to the model/NN \n",
    "2. block_size = 8 means this tensor consists of 8 examples to train the NN\n",
    "3. In such a way that, prediction is done at every 'step' in this block - when the model gets input 5962 its task is to predict 22307 and so on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e1ccae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5962, 22307,    25,   198,  8421,   356,  5120,   597,  2252])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0787f1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170e3f8f",
   "metadata": {},
   "source": [
    "## batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab66c6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split, bch_sze = 4, blk_sze = 8):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(blk_sze, len(data), (bch_sze,)) #get random indexes from our data of size batch_size\n",
    "    x = torch.stack([data[i:i+blk_sze] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+blk_sze] for i in ix])\n",
    "    x, y = x.to(train_config['device']), y.to(train_config['device'])\n",
    "    return x,y\n",
    "\n",
    "xb, yb = get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e18568d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  818, 36797,   810,  1659,    11,   749,  2612,   813],\n",
       "         [49275,  1677,    40,  2937,    25,   198,   464, 16339],\n",
       "         [  440,  1296,    11,   198,  2437,  1690,   288,   455],\n",
       "         [   13,  1867, 27563,   992,  5891,   338,   326,    30]],\n",
       "        device='mps:0'),\n",
       " tensor([[36797,   810,  1659,    11,   749,  2612,   813],\n",
       "         [ 1677,    40,  2937,    25,   198,   464, 16339],\n",
       "         [ 1296,    11,   198,  2437,  1690,   288,   455],\n",
       "         [ 1867, 27563,   992,  5891,   338,   326,    30]], device='mps:0'))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb #size (B,T) tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ffb54fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.pos_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.sa_head = Head(n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "    \n",
    "    def forward(self, idx, targets=None):\n",
    "        B,T = idx.shape\n",
    "        #idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.pos_embedding_table(torch.arange(T)) #(T,C)\n",
    "        x = tok_emb+pos_emb # (B,T,C)+(T,C) --> (B,T,C) (broadcasting)\n",
    "        x = self.sa_head(x)\n",
    "        logits = self.lm_head(x) # (B,T, vocab_size)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        #idx is a (B,T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            #crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            #get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B,C)\n",
    "            probs = F.softmax(logits, dim=-1) # (B,C)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) #(B,1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        \n",
    "        return idx\n",
    "    \n",
    "class Head(nn.Module):\n",
    "    \"\"\"one head of self-attention\"\"\"\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd,head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        w = q @ k.transpose(-2,-1) * C**-0.5\n",
    "        w = w.masked_fill(self.tril==0, float('-inf'))\n",
    "        w = F.softmax(w, dim=-1)\n",
    "        v = self.value(x)\n",
    "        out = w@v\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab59cc31",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "empty(): argument 'size' must be tuple of SymInts, but found element of type tuple at pos 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [39], line 5\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_embedding_table \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_embd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_embedding_table \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mEmbedding(block_size, n_embd)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msa_head \u001b[38;5;241m=\u001b[39m Head(n_embd)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch_safe/lib/python3.9/site-packages/torch/nn/modules/sparse.py:142\u001b[0m, in \u001b[0;36mEmbedding.__init__\u001b[0;34m(self, num_embeddings, embedding_dim, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse, _weight, _freeze, device, dtype)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_grad_by_freq \u001b[38;5;241m=\u001b[39m scale_grad_by_freq\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m Parameter(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    143\u001b[0m                             requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m _freeze)\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_parameters()\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: empty(): argument 'size' must be tuple of SymInts, but found element of type tuple at pos 2"
     ]
    }
   ],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fe59a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
